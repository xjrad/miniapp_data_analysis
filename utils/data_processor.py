# utils/data_processor.py
# ğŸ“ˆ æ•°æ®å¤„ç†å·¥å…·æ¨¡å—

import pandas as pd
import re
from urllib.parse import urlparse
from datetime import datetime, timedelta
from config import get_config

# è·å–é…ç½®
config = get_config()

def format_event_name(event):
    """
    æ ¼å¼åŒ–äº‹ä»¶æ˜¾ç¤ºåç§°
    
    Args:
        event (str): åŸå§‹äº‹ä»¶åç§°
        
    Returns:
        str: æ ¼å¼åŒ–åçš„äº‹ä»¶åç§°
    """
    if not event:
        return "æœªçŸ¥äº‹ä»¶"
        
    # ä»é…ç½®ä¸­è·å–æ˜ å°„
    formatted_name = config.EVENT_NAME_MAPPING.get(event, event)
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ å°„ï¼Œè¿›è¡ŒåŸºæœ¬æ ¼å¼åŒ–
    if formatted_name == event:
        formatted_name = event.replace('$MP', '').replace('$', '').replace('_', ' ').title()
        if not formatted_name:
            formatted_name = event
    
    return formatted_name

def clean_page_path(path):
    """
    æ¸…ç†é¡µé¢è·¯å¾„
    
    Args:
        path (str): åŸå§‹é¡µé¢è·¯å¾„
        
    Returns:
        str: æ¸…ç†åçš„é¡µé¢è·¯å¾„
    """
    if pd.isna(path) or str(path).lower() in config.EXCLUDED_PATHS:
        return 'unknown'
    
    path_str = str(path)
    
    # å¦‚æœæ˜¯å®Œæ•´çš„pagesè·¯å¾„ï¼Œæå–é¡µé¢åç§°
    if path_str.startswith('pages/'):
        path_str = path_str.replace('pages/', '')
        path_str = path_str.replace('tabBar/', '')
        if '/' in path_str:
            path_str = path_str.split('/')[-1]
    
    # ç§»é™¤æŸ¥è¯¢å‚æ•°
    if '?' in path_str:
        path_str = path_str.split('?')[0]
    
    # ç§»é™¤æ–‡ä»¶æ‰©å±•å
    if '.' in path_str:
        name, ext = path_str.rsplit('.', 1)
        if ext in ['html', 'htm', 'php', 'jsp', 'asp']:
            path_str = name
    
    # å¦‚æœè·¯å¾„ä¸ºç©ºæˆ–åªæœ‰æ–œæ ï¼Œè¿”å›unknown
    if not path_str or path_str in ['/', '']:
        return 'unknown'
    
    return path_str

def extract_domain_from_url(url):
    """
    ä»URLä¸­æå–åŸŸå
    
    Args:
        url (str): å®Œæ•´URL
        
    Returns:
        str: åŸŸå
    """
    if not url or url.strip() == '':
        return 'direct'
        
    try:
        parsed = urlparse(url)
        domain = parsed.netloc
        
        if not domain:
            return 'direct'
            
        # ç§»é™¤wwwå‰ç¼€
        if domain.startswith('www.'):
            domain = domain[4:]
            
        return domain
        
    except Exception:
        return 'unknown'

def categorize_referrer(referrer):
    """
    åˆ†ç±»æ¥æºæ¸ é“
    
    Args:
        referrer (str): æ¥æºURL
        
    Returns:
        tuple: (åˆ†ç±», æ˜¾ç¤ºåç§°)
    """
    if not referrer or referrer.strip() == '':
        return 'direct', 'ç›´æ¥è®¿é—®'
        
    domain = extract_domain_from_url(referrer)
    
    # ä»é…ç½®ä¸­åŒ¹é…å·²çŸ¥æ¥æº
    for key, name in config.REFERRER_MAPPING.items():
        if key in domain.lower():
            return key, name
    
    return domain, f"æ¥æº: {domain}"

def get_time_condition(time_range):
    """
    æ ¹æ®æ—¶é—´èŒƒå›´ç”ŸæˆæŸ¥è¯¢æ¡ä»¶
    
    Args:
        time_range (str): æ—¶é—´èŒƒå›´æ ‡è¯†
        
    Returns:
        str: SQLæ—¶é—´æ¡ä»¶è¯­å¥
    """
    now = datetime.now()
    
    if time_range == 'today':
        start_time = now.replace(hour=0, minute=0, second=0, microsecond=0)
        end_time = now
    elif time_range == 'yesterday':
        start_time = now.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=1)
        end_time = now.replace(hour=0, minute=0, second=0, microsecond=0)
    elif time_range == 'last7days':
        start_time = now - timedelta(days=7)
        end_time = now
    elif time_range == 'last30days':
        start_time = now - timedelta(days=30)
        end_time = now
    else:
        return ""
    
    start_timestamp = int(start_time.timestamp())
    end_timestamp = int(end_time.timestamp())
    
    return f"AND created_at BETWEEN {start_timestamp} AND {end_timestamp}"

def extract_json_property(all_json, property_path, default=None):
    """
    ä»JSONå­—æ®µä¸­æå–å±æ€§å€¼
    
    Args:
        all_json (str): JSONå­—ç¬¦ä¸²
        property_path (str): å±æ€§è·¯å¾„ï¼Œå¦‚ '$.properties."$url_path"'
        default: é»˜è®¤å€¼
        
    Returns:
        any: æå–çš„å€¼æˆ–é»˜è®¤å€¼
    """
    try:
        if not all_json:
            return default
            
        import json
        data = json.loads(all_json)
        
        # ç®€å•çš„è·¯å¾„è§£æ
        if property_path.startswith('$.properties.'):
            prop_name = property_path.replace('$.properties.', '').strip('"')
            properties = data.get('properties', {})
            return properties.get(prop_name, default)
        elif property_path.startswith('$.'):
            prop_name = property_path.replace('$.', '').strip('"')
            return data.get(prop_name, default)
        else:
            return default
            
    except Exception:
        return default

def build_comprehensive_step_identifier(row):
    """
    æ„å»ºç»¼åˆæ­¥éª¤æ ‡è¯†ç¬¦
    
    Args:
        row (pandas.Series): æ•°æ®è¡Œ
        
    Returns:
        str: æ­¥éª¤æ ‡è¯†ç¬¦
    """
    event = row.get('event', '')
    clean_path = row.get('clean_path', '')
    page_title = row.get('page_title', '')
    url = row.get('url', '')
    referrer = row.get('referrer', '')
    screen_name = row.get('screen_name', '')
    element_content = row.get('element_content', '')
    
    # æ ¼å¼åŒ–äº‹ä»¶åç§°
    formatted_event = format_event_name(event)
    
    # æ„å»ºæ­¥éª¤æ ‡è¯†ç¬¦ - ä¼˜å…ˆçº§ï¼šé¡µé¢æ ‡é¢˜ > å±å¹•åç§° > é¡µé¢è·¯å¾„ > URLè·¯å¾„ > å…ƒç´ å†…å®¹
    identifier_parts = [formatted_event]
    
    if page_title and len(str(page_title).strip()) > 0:
        identifier_parts.append(f"({str(page_title)[:20]})")
    elif screen_name and len(str(screen_name).strip()) > 0:
        identifier_parts.append(f"({str(screen_name)[:20]})")
    elif clean_path and clean_path != 'unknown':
        identifier_parts.append(f"({clean_path})")
    elif url and len(str(url).strip()) > 0:
        try:
            parsed = urlparse(str(url))
            path = parsed.path if parsed.path and parsed.path != '/' else parsed.netloc
            if path:
                clean_url_path = clean_page_path(path)
                if clean_url_path != 'unknown':
                    identifier_parts.append(f"({clean_url_path})")
        except:
            pass
    elif element_content and len(str(element_content).strip()) > 0:
        content = str(element_content).strip()[:15]
        identifier_parts.append(f"[{content}]")
    
    return "".join(identifier_parts)

def apply_path_length_filter(path_sequence, path_length):
    """
    åº”ç”¨è·¯å¾„é•¿åº¦ç­›é€‰
    
    Args:
        path_sequence (list): è·¯å¾„åºåˆ—
        path_length (str): è·¯å¾„é•¿åº¦æ¡ä»¶
        
    Returns:
        bool: æ˜¯å¦ç¬¦åˆæ¡ä»¶
    """
    length = len(path_sequence)
    
    if path_length == 'all':
        return True
    elif path_length == '2-3':
        return 2 <= length <= 3
    elif path_length == '4-5':
        return 4 <= length <= 5
    elif path_length == '6-8':
        return 6 <= length <= 8
    elif path_length == '9+':
        return length >= 9
    
    return True

def preprocess_dataframe(df):
    """
    é¢„å¤„ç†DataFrame
    
    Args:
        df (pandas.DataFrame): åŸå§‹æ•°æ®
        
    Returns:
        pandas.DataFrame: é¢„å¤„ç†åçš„æ•°æ®
    """
    if df.empty:
        return df
    
    # æ•°æ®é¢„å¤„ç†
    df['timestamp'] = pd.to_datetime(df['created_at'], unit='s')
    df['clean_path'] = df['url_path'].apply(clean_page_path)
    df['event_duration'] = pd.to_numeric(df.get('event_duration', 0), errors='coerce').fillna(0)
    
    # æ„å»ºæ­¥éª¤æ ‡è¯†ï¼ˆç»¼åˆå¤šä¸ªç»´åº¦ï¼‰
    df['step_identifier'] = df.apply(lambda row: build_comprehensive_step_identifier(row), axis=1)
    
    return df

def generate_mock_trend_data(time_range):
    """
    ç”Ÿæˆæ¨¡æ‹Ÿè¶‹åŠ¿æ•°æ®
    
    Args:
        time_range (str): æ—¶é—´èŒƒå›´
        
    Returns:
        dict: è¶‹åŠ¿æ•°æ®
    """
    if time_range == 'today':
        dates = [(datetime.now() - timedelta(hours=i)).strftime('%H:00') for i in range(23, -1, -1)]
        uv = [max(10, 50 + i * 2 + (i % 3) * 10) for i in range(24)]
        pv = [max(20, int(uv[i] * (2 + (i % 4) * 0.5))) for i in range(24)]
    else:
        days = {'yesterday': 1, 'last7days': 7, 'last30days': 30}.get(time_range, 7)
        dates = [(datetime.now() - timedelta(days=i)).strftime('%m-%d') for i in range(days-1, -1, -1)]
        uv = [max(50, 200 + i * 10 + (i % 5) * 20) for i in range(days)]
        pv = [max(100, int(uv[i] * (3 + (i % 3) * 0.8))) for i in range(days)]
    
    return {'dates': dates, 'uv': uv, 'pv': pv}

def generate_mock_hourly_data():
    """
    ç”Ÿæˆ24å°æ—¶çƒ­åŠ›å›¾æ¨¡æ‹Ÿæ•°æ®
    
    Returns:
        dict: å°æ—¶æ•°æ®
    """
    hourly_data = []
    for hour in range(24):
        for day in range(7):
            if 9 <= hour <= 18:
                activity = max(50, 100 + (hour - 12) ** 2 * 5 + day * 10)
            elif 19 <= hour <= 23:
                activity = max(30, 80 - (hour - 21) ** 2 * 3 + day * 5)
            else:
                activity = max(5, 20 - hour + day * 2)
            
            hourly_data.append([hour, day, int(activity)])
    
    return {'hourlyData': hourly_data}